{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9673e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Environment import cryptoTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ef425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "def convet_to_ragged_tensor(obs, single=True):\n",
    "    # Make sure nesting depth is consistent\n",
    "    if single:\n",
    "        for i, value in enumerate(obs):\n",
    "            if not isinstance(value, list):\n",
    "                obs[i] = list([value])\n",
    "\n",
    "        return tf.ragged.constant([obs])\n",
    "\n",
    "    else:\n",
    "        for i, entry in enumerate(obs):\n",
    "            for j, value in enumerate(entry):\n",
    "                if not isinstance(value, list):\n",
    "                    obs[i][j] = list([value])\n",
    "\n",
    "        return tf.ragged.constant(obs)\n",
    "    \n",
    "init = tf.keras.initializers.he_uniform(seed=None)\n",
    "\n",
    "def agent(observation_space, action_space):\n",
    "    \n",
    "    # Convert input to a ragged tensor\n",
    "    observation_space_tensor = convet_to_ragged_tensor(observation_space)\n",
    "    \n",
    "    # Get maximum sequence length\n",
    "    max_seq = observation_space_tensor.bounding_shape()[-1]\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=[None, max_seq], dtype=tf.float32, ragged=True),\n",
    "        tf.keras.layers.LSTM(64, kernel_initializer=init),\n",
    "        tf.keras.layers.Dense(len(action_space), activation='linear', kernel_initializer=init)\n",
    "    ])\n",
    "    \n",
    "    # Can also use Huber loss?\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ea2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, memory, model, target_model, done):\n",
    "    learning_rate = 0.7\n",
    "    discount_factor = 0.9\n",
    "    \n",
    "    MIN_REPLAY_SIZE = 1000\n",
    "    if len(memory) < MIN_REPLAY_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_size = 64\n",
    "    mini_batch_indexes = np.random.choice(np.arange(len(memory)), size=batch_size, replace=False)\n",
    "\n",
    "    current_states = [memory[i][0] for i in mini_batch_indexes]\n",
    "    current_qs_list = model.predict(convet_to_ragged_tensor(current_states, single=False))\n",
    "    \n",
    "    new_current_states = [memory[i][3] for i in mini_batch_indexes]\n",
    "    future_qs_list = target_model.predict(convet_to_ragged_tensor(new_current_states, single=False))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, i in enumerate(mini_batch_indexes):\n",
    "        (observation, action, reward, new_observation, done) = memory[i]\n",
    "        if not done:\n",
    "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "        else:\n",
    "            max_future_q = reward\n",
    "\n",
    "        current_qs = current_qs_list[index]\n",
    "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\n",
    "\n",
    "        X.append(observation)\n",
    "        Y.append(current_qs)\n",
    "    \n",
    "    X = convet_to_ragged_tensor(X, single=False)\n",
    "    model.fit(X, np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba4bf0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: -68981142.37 after n steps = 0 with final reward = -1964840.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 17726838.199999962 after n steps = 1 with final reward = 147363.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1092511311.3300002 after n steps = 2 with final reward = 1817477.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1191900145.8300002 after n steps = 3 with final reward = 11789040.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1988990188.9499996 after n steps = 4 with final reward = 13606517.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -34975265.10999998 after n steps = 5 with final reward = 491210.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2144544637.010001 after n steps = 6 with final reward = 12574976.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -298928132.5800001 after n steps = 7 with final reward = -1915719.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 966582143.6299994 after n steps = 8 with final reward = 2357808.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2784291866.2400007 after n steps = 9 with final reward = 17880044.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1020622523.0099993 after n steps = 10 with final reward = 7859360.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2874460574.8999996 after n steps = 11 with final reward = 19599279.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2308149381.9699993 after n steps = 12 with final reward = 16259051.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1541224355.52 after n steps = 13 with final reward = 12525855.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1653490082.06 after n steps = 14 with final reward = 11150467.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 808234244.5999997 after n steps = 15 with final reward = 12427613.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4116369676.669999 after n steps = 16 with final reward = 27360397.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2142326540.84 after n steps = 17 with final reward = 15866083.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1517940595.1999998 after n steps = 18 with final reward = 16259051.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3218124920.329999 after n steps = 19 with final reward = 19157190.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2817034805.7700005 after n steps = 20 with final reward = 19648400.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 1754482433.9700003 after n steps = 21 with final reward = 15473115.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3579101031.0100017 after n steps = 22 with final reward = 29963810.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3506419429.9800014 after n steps = 23 with final reward = 28146333.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 2726670530.4199996 after n steps = 24 with final reward = 17732681.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3955974161.640002 after n steps = 25 with final reward = 36496903.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3134639972.1800017 after n steps = 26 with final reward = 22743023.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3288475598.2000017 after n steps = 27 with final reward = 29718205.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5383802048.65 after n steps = 28 with final reward = 32518102.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4762981059.1900015 after n steps = 29 with final reward = 35563604.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4535784094.319998 after n steps = 30 with final reward = 32321618.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4254827537.6700025 after n steps = 31 with final reward = 33304038.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4813099517.529998 after n steps = 32 with final reward = 38167017.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4241309101.8599977 after n steps = 33 with final reward = 33107554.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5210666309.389998 after n steps = 34 with final reward = 35170636.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4394589561.129997 after n steps = 35 with final reward = 34679426.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 3887042656.980001 after n steps = 36 with final reward = 30553262.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5678846850.969998 after n steps = 37 with final reward = 41752850.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 4567616810.540001 after n steps = 38 with final reward = 38609106.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5827554600.780001 after n steps = 39 with final reward = 47156160.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6416446959.45 after n steps = 40 with final reward = 46615829.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6113755045.299999 after n steps = 41 with final reward = 42440544.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5510631996.689996 after n steps = 42 with final reward = 40131857.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5889134594.139998 after n steps = 43 with final reward = 47401765.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5275288511.320002 after n steps = 44 with final reward = 41163398.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6292472083.189999 after n steps = 45 with final reward = 46271982.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5657043819.400001 after n steps = 46 with final reward = 47450886.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5879487176.229997 after n steps = 47 with final reward = 37675807.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6384031389.53 after n steps = 48 with final reward = 51577050.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5396547676.310001 after n steps = 49 with final reward = 44601868.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5562114459.670002 after n steps = 50 with final reward = 43570327.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6836759541.079994 after n steps = 51 with final reward = 49808694.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6539665741.319999 after n steps = 52 with final reward = 49956057.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7048237879.309998 after n steps = 53 with final reward = 52559470.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5756301026.569998 after n steps = 54 with final reward = 48236822.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6498197649.520006 after n steps = 55 with final reward = 46075498.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7240192883.929999 after n steps = 56 with final reward = 51675292.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6443571131.65 after n steps = 57 with final reward = 47843854.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7023980045.590001 after n steps = 58 with final reward = 54131342.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8714241094.310001 after n steps = 59 with final reward = 65036204.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7900537934.249999 after n steps = 60 with final reward = 58601353.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7746433319.850001 after n steps = 61 with final reward = 59632894.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8287526678.12 after n steps = 62 with final reward = 58159264.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8138105080.340005 after n steps = 63 with final reward = 58994321.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7451927831.3099985 after n steps = 64 with final reward = 51134961.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6446048334.789998 after n steps = 65 with final reward = 46959676.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8981642437.33 after n steps = 66 with final reward = 64397631.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 7596736672.509998 after n steps = 67 with final reward = 57766296.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8061846451.650001 after n steps = 68 with final reward = 61941581.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8493351627.100004 after n steps = 69 with final reward = 69260610.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9664675381.390001 after n steps = 70 with final reward = 73877984.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8095699566.530004 after n steps = 71 with final reward = 59190805.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8845203324.02 after n steps = 72 with final reward = 66755439.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8836073846.66 after n steps = 73 with final reward = 63759058.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8865443434.32 after n steps = 74 with final reward = 67197528.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8658053571.459995 after n steps = 75 with final reward = 67394012.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8850297501.859999 after n steps = 76 with final reward = 63071364.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8720610335.880001 after n steps = 77 with final reward = 61352129.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9985253741.180002 after n steps = 78 with final reward = 75891945.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9014225088.890007 after n steps = 79 with final reward = 65871261.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8774546945.979996 after n steps = 80 with final reward = 67197528.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10289314864.169996 after n steps = 81 with final reward = 75891945.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10526955054.450003 after n steps = 82 with final reward = 77316454.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8378375949.429997 after n steps = 83 with final reward = 64692357.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8040985071.010001 after n steps = 84 with final reward = 64741478.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9964538607.400002 after n steps = 85 with final reward = 72551717.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9170233695.190002 after n steps = 86 with final reward = 68081706.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10936732490.869997 after n steps = 87 with final reward = 80018109.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8122847232.8499975 after n steps = 88 with final reward = 65085325.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8103168771.170001 after n steps = 89 with final reward = 66558955.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9057477184.32 after n steps = 90 with final reward = 73042927.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9908981608.740002 after n steps = 91 with final reward = 75990187.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11968694403.449997 after n steps = 92 with final reward = 90726487.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9918443843.55 after n steps = 93 with final reward = 72502596.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10529465821.75 after n steps = 94 with final reward = 78347995.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10954229117.809998 after n steps = 95 with final reward = 81589981.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10636594315.370007 after n steps = 96 with final reward = 79084810.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 8858601119.49 after n steps = 97 with final reward = 69015005.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10617577457.659998 after n steps = 98 with final reward = 78053269.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10494912283.609997 after n steps = 99 with final reward = 82032070.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10182139636.599995 after n steps = 100 with final reward = 74860404.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10460046875.35 after n steps = 101 with final reward = 78642721.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11741686117.87 after n steps = 102 with final reward = 85765266.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11927455307.069998 after n steps = 103 with final reward = 87091533.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10859015886.96 after n steps = 104 with final reward = 77611180.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11069678243.499996 after n steps = 105 with final reward = 81540860.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9127719147.720001 after n steps = 106 with final reward = 74762162.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11029193920.449999 after n steps = 107 with final reward = 85716145.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 9768456161.88001 after n steps = 108 with final reward = 79625141.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11028523058.310003 after n steps = 109 with final reward = 82621522.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11861963405.419998 after n steps = 110 with final reward = 91758028.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11417125153.28 after n steps = 111 with final reward = 87975711.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11149493873.48 after n steps = 112 with final reward = 83210974.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10548460137.350006 after n steps = 113 with final reward = 83603942.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10509736077.830006 after n steps = 114 with final reward = 84242515.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11919883796.540005 after n steps = 115 with final reward = 91856270.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11587670565.959995 after n steps = 116 with final reward = 86993291.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11955399253.000002 after n steps = 117 with final reward = 88614284.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10604249897.900002 after n steps = 118 with final reward = 82818006.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11784444537.210009 after n steps = 119 with final reward = 91119455.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12334650943.330008 after n steps = 120 with final reward = 93477263.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12676954611.62 after n steps = 121 with final reward = 92593085.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12618495386.799997 after n steps = 122 with final reward = 91807149.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11568829657.25 after n steps = 123 with final reward = 89596704.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12798289418.669994 after n steps = 124 with final reward = 93821110.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12358152067.800003 after n steps = 125 with final reward = 95736829.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11498486882.11 after n steps = 126 with final reward = 86895049.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12331880274.679998 after n steps = 127 with final reward = 95392982.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12821102309.800001 after n steps = 128 with final reward = 94459683.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11839891077.800001 after n steps = 129 with final reward = 90922971.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10615350947.36001 after n steps = 130 with final reward = 84930209.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13096334655.169994 after n steps = 131 with final reward = 95933313.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12824719903.490007 after n steps = 132 with final reward = 93575505.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12018917841.650005 after n steps = 133 with final reward = 91708907.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12556583633.360006 after n steps = 134 with final reward = 96326281.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13215843152.499992 after n steps = 135 with final reward = 93182537.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11364044110.069996 after n steps = 136 with final reward = 93133416.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13248136103.689995 after n steps = 137 with final reward = 99027936.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11482396418.959995 after n steps = 138 with final reward = 85028451.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13176518455.130014 after n steps = 139 with final reward = 96670128.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13436171136.219997 after n steps = 140 with final reward = 97554306.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13793757425.270008 after n steps = 141 with final reward = 101434865.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12330433699.889997 after n steps = 142 with final reward = 94705288.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12365720581.850002 after n steps = 143 with final reward = 93821110.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12921326671.219992 after n steps = 144 with final reward = 97898153.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13184799481.210007 after n steps = 145 with final reward = 96670128.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12239266554.139994 after n steps = 146 with final reward = 94508804.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13501759358.980005 after n steps = 147 with final reward = 103596189.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11960763750.179995 after n steps = 148 with final reward = 93329900.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13602465802.550007 after n steps = 149 with final reward = 101336623.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12179585618.730001 after n steps = 150 with final reward = 94312320.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13057186962.380001 after n steps = 151 with final reward = 94950893.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13203833196.079992 after n steps = 152 with final reward = 98340242.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12835627888.590004 after n steps = 153 with final reward = 91758028.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13275625326.089993 after n steps = 154 with final reward = 102073438.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12248862770.350002 after n steps = 155 with final reward = 98291121.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13619774230.130007 after n steps = 156 with final reward = 100403324.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12698201189.249992 after n steps = 157 with final reward = 97112217.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14619731898.020006 after n steps = 158 with final reward = 107329385.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12539307682.369999 after n steps = 159 with final reward = 97505185.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12710402615.019999 after n steps = 160 with final reward = 98340242.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13002607070.419996 after n steps = 161 with final reward = 100845413.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12234664694.87 after n steps = 162 with final reward = 94214078.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13160342718.850006 after n steps = 163 with final reward = 100698050.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12736926411.430002 after n steps = 164 with final reward = 99224420.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13483372133.949997 after n steps = 165 with final reward = 104578609.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14177743369.990005 after n steps = 166 with final reward = 106838175.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12773790550.209997 after n steps = 167 with final reward = 99568267.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13407116582.150002 after n steps = 168 with final reward = 99813872.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13537045181.740004 after n steps = 169 with final reward = 101926075.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14482626440.37001 after n steps = 170 with final reward = 106887296.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13714293474.359999 after n steps = 171 with final reward = 104578609.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 12840848859.430002 after n steps = 172 with final reward = 97603427.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13932838682.029995 after n steps = 173 with final reward = 105757513.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14681879014.920004 after n steps = 174 with final reward = 108213563.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13803785427.15 after n steps = 175 with final reward = 105020698.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13594639222.970003 after n steps = 176 with final reward = 103154100.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14078454039.250002 after n steps = 177 with final reward = 106003118.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13964094576.289986 after n steps = 178 with final reward = 103350584.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14008328383.709995 after n steps = 179 with final reward = 106494328.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14160088584.450008 after n steps = 180 with final reward = 105217182.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13390734171.79 after n steps = 181 with final reward = 101287502.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14285400149.49 after n steps = 182 with final reward = 109490709.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13214329052.909992 after n steps = 183 with final reward = 100108598.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13921841076.08 after n steps = 184 with final reward = 103940036.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14494273404.269995 after n steps = 185 with final reward = 109785435.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13040342022.559996 after n steps = 186 with final reward = 101483986.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 13719366463.82 after n steps = 187 with final reward = 103743552.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14569644305.940008 after n steps = 188 with final reward = 107132901.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14474996167.660002 after n steps = 189 with final reward = 108360926.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14052868248.77 after n steps = 190 with final reward = 104185641.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14272221564.129995 after n steps = 191 with final reward = 104087399.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14879470170.289997 after n steps = 192 with final reward = 110129282.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 15096988284.170004 after n steps = 193 with final reward = 109981919.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 15071417486.709995 after n steps = 194 with final reward = 112880058.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14214022372.700008 after n steps = 195 with final reward = 107083780.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14234775741.529999 after n steps = 196 with final reward = 110178403.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14248699048.009998 after n steps = 197 with final reward = 107034659.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 15362665199.67 after n steps = 198 with final reward = 114451930.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 14982675576.739998 after n steps = 199 with final reward = 111357307.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    }
   ],
   "source": [
    "# The main loop\n",
    "\n",
    "data_path = \"../data/Coinbase_BTCUSD_dailydata.csv\"\n",
    "env = cryptoTrade(data_path)\n",
    "env.reset()\n",
    "\n",
    "epsilon, max_epsilon, min_epsilon = 1, 1, 0.01\n",
    "decay = 0.01\n",
    "\n",
    "model = agent(env.observation_space, env.action_space)\n",
    "target_model = agent(env.observation_space, env.action_space)\n",
    "target_model.set_weights(model.get_weights())\n",
    "\n",
    "memory = []\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "f = open(\"20220329_RNNTraining.txt\",\"w\")\n",
    "\n",
    "steps_to_update_target_model = 0\n",
    "for episode in range(200):\n",
    "    total_training_rewards = 0\n",
    "    \n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        steps_to_update_target_model += 1\n",
    "\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = int(np.random.choice(len(env.action_space)))\n",
    "        else: \n",
    "            # Choose the best action\n",
    "            action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "            \n",
    "        # Now step the simulation\n",
    "        new_observation, reward, done = env.step(action)\n",
    "        memory.append([observation, action, reward, new_observation, done])\n",
    "        \n",
    "        # Update the neural network\n",
    "        if steps_to_update_target_model % 4 ==0:#or done:\n",
    "            train(env, memory, model, target_model, done)\n",
    "            \n",
    "        #observation = new_observation\n",
    "        total_training_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            print('Total training rewards: {} after n steps = {} with final reward = {}'.format(total_training_rewards, episode, reward))\n",
    "            #total_training_rewards += 1\n",
    "            txt = \"{:.2f}\\n\"\n",
    "            f.write(txt.format(total_training_rewards))\n",
    "\n",
    "            if steps_to_update_target_model >= 100:\n",
    "                print('Copying main network weights to the target network weights')\n",
    "                target_model.set_weights(model.get_weights())\n",
    "                steps_to_update_target_model = 0\n",
    "            break\n",
    "        \n",
    "    # Update epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e7f2",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6574bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment to predict over\n",
    "observation = env.reset()\n",
    "done = False\n",
    "val_memory = []\n",
    "\n",
    "while not done:\n",
    "    action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "    new_observation, reward, done = env.step(action)\n",
    "    val_memory.append([observation, action, reward, new_observation, done])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1957e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>vol_fiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1645142400</td>\n",
       "      <td>40323.85</td>\n",
       "      <td>40972.30</td>\n",
       "      <td>40537.94</td>\n",
       "      <td>40659.51</td>\n",
       "      <td>3062.079456</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>1.245027e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1645056000</td>\n",
       "      <td>40099.99</td>\n",
       "      <td>44195.62</td>\n",
       "      <td>43895.55</td>\n",
       "      <td>40536.73</td>\n",
       "      <td>18630.108422</td>\n",
       "      <td>2022-02-17</td>\n",
       "      <td>7.552037e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1644969600</td>\n",
       "      <td>43330.59</td>\n",
       "      <td>44585.69</td>\n",
       "      <td>44580.73</td>\n",
       "      <td>43895.56</td>\n",
       "      <td>9663.440404</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>4.241821e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1644883200</td>\n",
       "      <td>42433.28</td>\n",
       "      <td>44775.96</td>\n",
       "      <td>42548.71</td>\n",
       "      <td>44583.52</td>\n",
       "      <td>14154.734526</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>6.310679e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1644796800</td>\n",
       "      <td>41570.00</td>\n",
       "      <td>42876.15</td>\n",
       "      <td>42073.37</td>\n",
       "      <td>42548.71</td>\n",
       "      <td>14805.983388</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>6.299755e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1619654400</td>\n",
       "      <td>52369.61</td>\n",
       "      <td>55226.86</td>\n",
       "      <td>54889.81</td>\n",
       "      <td>53580.00</td>\n",
       "      <td>14592.316888</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>7.818563e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1619568000</td>\n",
       "      <td>53887.00</td>\n",
       "      <td>56476.17</td>\n",
       "      <td>55069.61</td>\n",
       "      <td>54894.03</td>\n",
       "      <td>16484.336777</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>9.048917e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1619481600</td>\n",
       "      <td>53321.00</td>\n",
       "      <td>55509.39</td>\n",
       "      <td>54047.80</td>\n",
       "      <td>55069.62</td>\n",
       "      <td>13957.086495</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>7.686114e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1619395200</td>\n",
       "      <td>48817.62</td>\n",
       "      <td>54400.00</td>\n",
       "      <td>49121.00</td>\n",
       "      <td>54053.60</td>\n",
       "      <td>18005.223994</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>9.732472e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1619308800</td>\n",
       "      <td>47044.01</td>\n",
       "      <td>50591.38</td>\n",
       "      <td>50101.42</td>\n",
       "      <td>49121.00</td>\n",
       "      <td>14633.512065</td>\n",
       "      <td>2021-04-25</td>\n",
       "      <td>7.188127e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           unix       low      high      open     close        volume  \\\n",
       "0    1645142400  40323.85  40972.30  40537.94  40659.51   3062.079456   \n",
       "1    1645056000  40099.99  44195.62  43895.55  40536.73  18630.108422   \n",
       "2    1644969600  43330.59  44585.69  44580.73  43895.56   9663.440404   \n",
       "3    1644883200  42433.28  44775.96  42548.71  44583.52  14154.734526   \n",
       "4    1644796800  41570.00  42876.15  42073.37  42548.71  14805.983388   \n",
       "..          ...       ...       ...       ...       ...           ...   \n",
       "295  1619654400  52369.61  55226.86  54889.81  53580.00  14592.316888   \n",
       "296  1619568000  53887.00  56476.17  55069.61  54894.03  16484.336777   \n",
       "297  1619481600  53321.00  55509.39  54047.80  55069.62  13957.086495   \n",
       "298  1619395200  48817.62  54400.00  49121.00  54053.60  18005.223994   \n",
       "299  1619308800  47044.01  50591.38  50101.42  49121.00  14633.512065   \n",
       "\n",
       "           date      vol_fiat  \n",
       "0    2022-02-18  1.245027e+08  \n",
       "1    2022-02-17  7.552037e+08  \n",
       "2    2022-02-16  4.241821e+08  \n",
       "3    2022-02-15  6.310679e+08  \n",
       "4    2022-02-14  6.299755e+08  \n",
       "..          ...           ...  \n",
       "295  2021-04-29  7.818563e+08  \n",
       "296  2021-04-28  9.048917e+08  \n",
       "297  2021-04-27  7.686114e+08  \n",
       "298  2021-04-26  9.732472e+08  \n",
       "299  2021-04-25  7.188127e+08  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a simulation to see what happened\n",
    "data = env.data\n",
    "actions = np.array(val_memory, dtype=object)[:, 1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a528572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836860f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
