{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9673e235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Environment import cryptoTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ef425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "def convet_to_ragged_tensor(obs, single=True):\n",
    "    # Make sure nesting depth is consistent\n",
    "    if single:\n",
    "        for i, value in enumerate(obs):\n",
    "            if not isinstance(value, list):\n",
    "                obs[i] = list([value])\n",
    "\n",
    "        return tf.ragged.constant([obs])\n",
    "\n",
    "    else:\n",
    "        for i, entry in enumerate(obs):\n",
    "            for j, value in enumerate(entry):\n",
    "                if not isinstance(value, list):\n",
    "                    obs[i][j] = list([value])\n",
    "\n",
    "        return tf.ragged.constant(obs)\n",
    "    \n",
    "init = tf.keras.initializers.he_uniform(seed=None)\n",
    "\n",
    "def agent(observation_space, action_space):\n",
    "    \n",
    "    # Convert input to a ragged tensor\n",
    "    observation_space_tensor = convet_to_ragged_tensor(observation_space)\n",
    "    \n",
    "    # Get maximum sequence length\n",
    "    max_seq = observation_space_tensor.bounding_shape()[-1]\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=[None, max_seq], dtype=tf.float32, ragged=True),\n",
    "        tf.keras.layers.LSTM(64, kernel_initializer=init),\n",
    "        tf.keras.layers.Dense(len(action_space), activation='linear', kernel_initializer=init)\n",
    "    ])\n",
    "    \n",
    "    # Can also use Huber loss?\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31ea2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, memory, model, target_model, done):\n",
    "    learning_rate = 0.7\n",
    "    discount_factor = 0.6\n",
    "    \n",
    "    MIN_REPLAY_SIZE = 1000\n",
    "    if len(memory) < MIN_REPLAY_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_size = 64\n",
    "    mini_batch_indexes = np.random.choice(np.arange(len(memory)), size=batch_size, replace=False)\n",
    "\n",
    "    current_states = [memory[i][0] for i in mini_batch_indexes]\n",
    "    current_qs_list = model.predict(convet_to_ragged_tensor(current_states, single=False))\n",
    "    \n",
    "    new_current_states = [memory[i][3] for i in mini_batch_indexes]\n",
    "    future_qs_list = target_model.predict(convet_to_ragged_tensor(new_current_states, single=False))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, i in enumerate(mini_batch_indexes):\n",
    "        (observation, action, reward, new_observation, done) = memory[i]\n",
    "        if not done:\n",
    "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "        else:\n",
    "            max_future_q = reward\n",
    "\n",
    "        current_qs = current_qs_list[index]\n",
    "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\n",
    "\n",
    "        X.append(observation)\n",
    "        Y.append(current_qs)\n",
    "    \n",
    "    X = convet_to_ragged_tensor(X, single=False)\n",
    "    model.fit(X, np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4bf0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX SEQ tf.Tensor(10, shape=(), dtype=int64)\n",
      "(10, 256)\n",
      "MAX SEQ tf.Tensor(10, shape=(), dtype=int64)\n",
      "(10, 256)\n",
      "Total training rewards: -1214272562.18 after n steps = 0 with final reward = -7515513.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -248919875.25999996 after n steps = 1 with final reward = -1473630.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:09:40.481648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-28 19:09:40.519334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: 876495917.1900002 after n steps = 2 with final reward = 3438470.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:09:40.698608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-28 19:09:40.734374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-28 19:09:41.148614: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-28 19:09:41.267906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-28 19:09:41.335249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: 951442026.35 after n steps = 3 with final reward = 4077043.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 339294564.18 after n steps = 4 with final reward = 2406929.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -846976675.29 after n steps = 5 with final reward = -4912100.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 681500648.92 after n steps = 6 with final reward = 3684075.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1513475880.6599998 after n steps = 7 with final reward = -11985524.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1760244029.2499998 after n steps = 8 with final reward = -10266289.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4007587526.5800004 after n steps = 9 with final reward = -23185112.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1472284259.0699995 after n steps = 10 with final reward = -6140125.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1979673637.9300005 after n steps = 11 with final reward = -9676837.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1091224582.5700002 after n steps = 12 with final reward = -8154086.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1298467406.84 after n steps = 13 with final reward = -11346951.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1132991425.38 after n steps = 14 with final reward = -6729577.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1670285429.980001 after n steps = 15 with final reward = -12182008.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1081244526.7000003 after n steps = 16 with final reward = -5599794.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1922982964.93 after n steps = 17 with final reward = -16995866.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1569223553.4699998 after n steps = 18 with final reward = -14490695.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2543499725.1099987 after n steps = 19 with final reward = -18616859.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2060127792.5399997 after n steps = 20 with final reward = -17830923.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2919410847.4399996 after n steps = 21 with final reward = -21514998.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3051923862.5899997 after n steps = 22 with final reward = -26918308.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2263864915.71 after n steps = 23 with final reward = -17929165.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3754831263.920002 after n steps = 24 with final reward = -22743023.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3421521139.8400006 after n steps = 25 with final reward = -21023788.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3920245299.099998 after n steps = 26 with final reward = -25739404.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4240616346.6399975 after n steps = 27 with final reward = -21809724.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3705574818.5999994 after n steps = 28 with final reward = -22546539.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3933081272.32 after n steps = 29 with final reward = -27900728.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2175224715.589999 after n steps = 30 with final reward = -19206311.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2824765163.9599996 after n steps = 31 with final reward = -22988628.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3585899136.379999 after n steps = 32 with final reward = -28490180.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4245485851.1800017 after n steps = 33 with final reward = -29472600.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3301178906.1699986 after n steps = 34 with final reward = -25592041.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4705476214.849999 after n steps = 35 with final reward = -34679426.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4814069261.520004 after n steps = 36 with final reward = -33009312.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5142351694.329999 after n steps = 37 with final reward = -37233718.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5556664563.550001 after n steps = 38 with final reward = -34679426.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -3609454141.0900016 after n steps = 39 with final reward = -28244575.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4014817359.7600017 after n steps = 40 with final reward = -27262155.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4246019272.3399997 after n steps = 41 with final reward = -32714586.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5100982008.979998 after n steps = 42 with final reward = -43275601.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4619415105.620001 after n steps = 43 with final reward = -35268878.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4566235458.700002 after n steps = 44 with final reward = -33844369.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4763276802.16 after n steps = 45 with final reward = -34384700.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4210309620.410001 after n steps = 46 with final reward = -32370739.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4428256846.529999 after n steps = 47 with final reward = -32370739.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5690642702.410002 after n steps = 48 with final reward = -32714586.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5304972275.429999 after n steps = 49 with final reward = -44896594.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5094126174.410002 after n steps = 50 with final reward = -38707348.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5231866198.839999 after n steps = 51 with final reward = -44356263.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5279795208.840001 after n steps = 52 with final reward = -42342302.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5190795529.699998 after n steps = 53 with final reward = -42538786.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4873353645.9400015 after n steps = 54 with final reward = -38854711.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5609527800.489998 after n steps = 55 with final reward = -46517587.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5678806181.140001 after n steps = 56 with final reward = -42980875.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: -5236374304.129998 after n steps = 57 with final reward = -41409003.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5601320083.990005 after n steps = 58 with final reward = -44307142.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6923744270.210001 after n steps = 59 with final reward = -56292666.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5056756077.790003 after n steps = 60 with final reward = -41065156.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7694321294.919996 after n steps = 61 with final reward = -53296285.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6061537002.979998 after n steps = 62 with final reward = -46812313.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6110772749.060001 after n steps = 63 with final reward = -42489665.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5748297463.529999 after n steps = 64 with final reward = -45191320.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6045348358.53 after n steps = 65 with final reward = -48089459.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7320685691.000001 after n steps = 66 with final reward = -52264744.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6305017879.679998 after n steps = 67 with final reward = -49071879.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6344820643.969996 after n steps = 68 with final reward = -46959676.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5814817086.440001 after n steps = 69 with final reward = -46124619.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5973397207.910003 after n steps = 70 with final reward = -48875395.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6223251919.869996 after n steps = 71 with final reward = -48777153.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6542160626.089995 after n steps = 72 with final reward = -48384185.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6262488438.400001 after n steps = 73 with final reward = -47794733.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6572895972.560001 after n steps = 74 with final reward = -49415726.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6095722676.0300045 after n steps = 75 with final reward = -48384185.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5913413662.510005 after n steps = 76 with final reward = -42244060.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5613712519.719999 after n steps = 77 with final reward = -45535167.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7397384824.149993 after n steps = 78 with final reward = -54278705.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7273032433.6799965 after n steps = 79 with final reward = -55162883.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6426493275.719998 after n steps = 80 with final reward = -49956057.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6619160196.939998 after n steps = 81 with final reward = -50643751.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7306206710.919996 after n steps = 82 with final reward = -55408488.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7649431485.870001 after n steps = 83 with final reward = -58159264.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8094594785.23 after n steps = 84 with final reward = -60517072.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6764755194.150002 after n steps = 85 with final reward = -52117381.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6959533071.519999 after n steps = 86 with final reward = -54278705.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6678082617.2999935 after n steps = 87 with final reward = -45486046.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7291960970.640002 after n steps = 88 with final reward = -60615314.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7524643477.219998 after n steps = 89 with final reward = -52854196.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6693941486.399999 after n steps = 90 with final reward = -54720794.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7371642436.38 after n steps = 91 with final reward = -49759573.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8116704309.43 after n steps = 92 with final reward = -58748716.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -7706440076.859998 after n steps = 93 with final reward = -56636513.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8576732969.759991 after n steps = 94 with final reward = -64643236.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8282126628.800003 after n steps = 95 with final reward = -64888841.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8119891099.990003 after n steps = 96 with final reward = -61597734.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8332676954.960001 after n steps = 97 with final reward = -64397631.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8088376905.959999 after n steps = 98 with final reward = -64201147.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6789336105.629999 after n steps = 99 with final reward = -55801456.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8778019131.800003 after n steps = 100 with final reward = -64495873.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8091908414.040001 after n steps = 101 with final reward = -66215108.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8026914652.899998 after n steps = 102 with final reward = -58650474.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9030026232.100006 after n steps = 103 with final reward = -66215108.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -8405989443.269997 after n steps = 104 with final reward = -61352129.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 401259620.3799999 after n steps = 105 with final reward = 1424509.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 195806054.0000001 after n steps = 106 with final reward = 294726.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -398668954.0200001 after n steps = 107 with final reward = -2849018.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4836918241.620001 after n steps = 108 with final reward = -34237337.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4587418721.959999 after n steps = 109 with final reward = -35072394.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4525218776.39 after n steps = 110 with final reward = -34286458.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: -4358104697.5599985 after n steps = 111 with final reward = -37528444.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5180216178.560002 after n steps = 112 with final reward = -38707348.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4860074067.850003 after n steps = 113 with final reward = -36447782.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4921915141.509997 after n steps = 114 with final reward = -35514483.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5687113304.04 after n steps = 115 with final reward = -40573946.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4183810367.839998 after n steps = 116 with final reward = -34679426.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4986171196.340002 after n steps = 117 with final reward = -37282839.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5277342289.63 after n steps = 118 with final reward = -39591526.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -4523316157.239999 after n steps = 119 with final reward = -38314380.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5031263055.009999 after n steps = 120 with final reward = -39837131.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -13063128644.590002 after n steps = 121 with final reward = -95835071.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12475945069.060003 after n steps = 122 with final reward = -95933313.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11391156851.849997 after n steps = 123 with final reward = -85077572.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12662374534.289993 after n steps = 124 with final reward = -89940551.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -10886307763.589993 after n steps = 125 with final reward = -83898668.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11613842093.769997 after n steps = 126 with final reward = -88516042.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -13216467999.009993 after n steps = 127 with final reward = -99126178.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11251245207.299994 after n steps = 128 with final reward = -84046031.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12258201863.670002 after n steps = 129 with final reward = -93182537.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12064453188.719994 after n steps = 130 with final reward = -92347480.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11006040190.269999 after n steps = 131 with final reward = -86698565.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11548280642.209997 after n steps = 132 with final reward = -91070334.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -11774334044.910002 after n steps = 133 with final reward = -89842309.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12370509544.139994 after n steps = 134 with final reward = -91021213.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -13244559897.630001 after n steps = 135 with final reward = -98585847.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -12128653522.490004 after n steps = 136 with final reward = -91512423.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11460670228.859997 after n steps = 137 with final reward = 86109113.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10783752232.460001 after n steps = 138 with final reward = 85961750.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11819985990.31 after n steps = 139 with final reward = 83849547.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10673943578.15 after n steps = 140 with final reward = 79674262.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11359938865.749998 after n steps = 141 with final reward = 86109113.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11733754300.48 after n steps = 142 with final reward = 86158234.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11930413785.380009 after n steps = 143 with final reward = 85323177.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10884369713.079998 after n steps = 144 with final reward = 85372298.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10774519333.679996 after n steps = 145 with final reward = 80558440.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11514574804.890003 after n steps = 146 with final reward = 86010871.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11710593931.46 after n steps = 147 with final reward = 87779227.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11927929469.82 after n steps = 148 with final reward = 91856270.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10925786585.81 after n steps = 149 with final reward = 86944170.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10345916024.440002 after n steps = 150 with final reward = 80607561.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10974155162.699999 after n steps = 151 with final reward = 85323177.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11577950118.749998 after n steps = 152 with final reward = 88024832.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11848012455.120003 after n steps = 153 with final reward = 86207355.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 10712937638.889997 after n steps = 154 with final reward = 83260095.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11981810721.389996 after n steps = 155 with final reward = 90284398.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 11712085737.490007 after n steps = 156 with final reward = 90137035.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6393781513.169996 after n steps = 157 with final reward = -45682530.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5809808623.960001 after n steps = 158 with final reward = -43865053.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -6095093820.650002 after n steps = 159 with final reward = -44896594.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -5859089358.999998 after n steps = 160 with final reward = -41801971.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6372930013.960001 after n steps = 161 with final reward = 47696491.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 5445374307.219998 after n steps = 162 with final reward = 41752850.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: 6112454932.900003 after n steps = 163 with final reward = 47450886.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2086305120.2900004 after n steps = 164 with final reward = -15374873.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rewards: -1234633574.7599998 after n steps = 165 with final reward = -9234748.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1958834667.2 after n steps = 166 with final reward = -13655638.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1490222057.7199998 after n steps = 167 with final reward = -13164428.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1183486604.1199994 after n steps = 168 with final reward = -11543435.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1286777488.0199993 after n steps = 169 with final reward = -10855741.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -411485737.38000005 after n steps = 170 with final reward = -4568253.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2287632597.1200004 after n steps = 171 with final reward = -15767841.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1555428497.6199996 after n steps = 172 with final reward = -11396072.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2010747435.6500008 after n steps = 173 with final reward = -12476734.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1953996635.319999 after n steps = 174 with final reward = -12967944.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1923497229.470001 after n steps = 175 with final reward = -13753880.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1181782336.0800004 after n steps = 176 with final reward = -12034645.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1246903302.2000005 after n steps = 177 with final reward = -9382111.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1661358435.63 after n steps = 178 with final reward = -12869702.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -2154785146.9799995 after n steps = 179 with final reward = -13410033.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -898573207.8300005 after n steps = 180 with final reward = -8399691.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1601393642.1499999 after n steps = 181 with final reward = -13213549.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1369361205.0400007 after n steps = 182 with final reward = -10757499.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1674322786.2899995 after n steps = 183 with final reward = -12673218.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1697396028.0700004 after n steps = 184 with final reward = -14097727.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1636888178.9999998 after n steps = 185 with final reward = -11101346.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1599030168.550001 after n steps = 186 with final reward = -11150467.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1124959186.6399999 after n steps = 187 with final reward = -10708378.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -1541745834.3099995 after n steps = 188 with final reward = -12329371.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9524558093.439997 after n steps = 189 with final reward = -73141169.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9163055404.059996 after n steps = 190 with final reward = -69751820.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9589818347.31 after n steps = 191 with final reward = -72109628.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9401293190.440002 after n steps = 192 with final reward = -73042927.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9517108244.450005 after n steps = 193 with final reward = -71814902.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9721515494.999996 after n steps = 194 with final reward = -73681500.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9630414917.190002 after n steps = 195 with final reward = -72256991.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9293660572.77 after n steps = 196 with final reward = -70832482.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9754700623.07 after n steps = 197 with final reward = -70586877.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -9853693680.309998 after n steps = 198 with final reward = -71421934.0\n",
      "Copying main network weights to the target network weights\n",
      "Total training rewards: -10074522171.669998 after n steps = 199 with final reward = -73386774.0\n",
      "Copying main network weights to the target network weights\n"
     ]
    }
   ],
   "source": [
    "# The main loop\n",
    "\n",
    "data_path = \"../data/Coinbase_BTCUSD_dailydata.csv\"\n",
    "env = cryptoTrade(data_path)\n",
    "env.reset()\n",
    "\n",
    "epsilon, max_epsilon, min_epsilon = 1, 1, 0.01\n",
    "decay = 0.01\n",
    "\n",
    "model = agent(env.observation_space, env.action_space)\n",
    "target_model = agent(env.observation_space, env.action_space)\n",
    "target_model.set_weights(model.get_weights())\n",
    "\n",
    "memory = []\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "steps_to_update_target_model = 0\n",
    "for episode in range(200):\n",
    "    total_training_rewards = 0\n",
    "    \n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        steps_to_update_target_model += 1\n",
    "\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = int(np.random.choice(len(env.action_space)))\n",
    "        else: \n",
    "            # Choose the best action\n",
    "            action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "            \n",
    "        # Now step the simulation\n",
    "        new_observation, reward, done = env.step(action)\n",
    "        memory.append([observation, action, reward, new_observation, done])\n",
    "        \n",
    "        # Update the neural network\n",
    "        if steps_to_update_target_model % 4 ==0:#or done:\n",
    "            train(env, memory, model, target_model, done)\n",
    "            \n",
    "        #observation = new_observation\n",
    "        total_training_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            print('Total training rewards: {} after n steps = {} with final reward = {}'.format(total_training_rewards, episode, reward))\n",
    "            total_training_rewards += 1\n",
    "\n",
    "            if steps_to_update_target_model >= 100:\n",
    "                print('Copying main network weights to the target network weights')\n",
    "                target_model.set_weights(model.get_weights())\n",
    "                steps_to_update_target_model = 0\n",
    "            break\n",
    "        \n",
    "    # Update epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e7f2",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f6574bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment to predict over\n",
    "observation = env.reset()\n",
    "done = False\n",
    "val_memory = []\n",
    "\n",
    "while not done:\n",
    "    action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "    new_observation, reward, done = env.step(action)\n",
    "    val_memory.append([observation, action, reward, new_observation, done])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81a1957e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>vol_fiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1645142400</td>\n",
       "      <td>40323.85</td>\n",
       "      <td>40972.30</td>\n",
       "      <td>40537.94</td>\n",
       "      <td>40659.51</td>\n",
       "      <td>3062.079456</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>1.245027e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1645056000</td>\n",
       "      <td>40099.99</td>\n",
       "      <td>44195.62</td>\n",
       "      <td>43895.55</td>\n",
       "      <td>40536.73</td>\n",
       "      <td>18630.108422</td>\n",
       "      <td>2022-02-17</td>\n",
       "      <td>7.552037e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1644969600</td>\n",
       "      <td>43330.59</td>\n",
       "      <td>44585.69</td>\n",
       "      <td>44580.73</td>\n",
       "      <td>43895.56</td>\n",
       "      <td>9663.440404</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>4.241821e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1644883200</td>\n",
       "      <td>42433.28</td>\n",
       "      <td>44775.96</td>\n",
       "      <td>42548.71</td>\n",
       "      <td>44583.52</td>\n",
       "      <td>14154.734526</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>6.310679e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1644796800</td>\n",
       "      <td>41570.00</td>\n",
       "      <td>42876.15</td>\n",
       "      <td>42073.37</td>\n",
       "      <td>42548.71</td>\n",
       "      <td>14805.983388</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>6.299755e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1619654400</td>\n",
       "      <td>52369.61</td>\n",
       "      <td>55226.86</td>\n",
       "      <td>54889.81</td>\n",
       "      <td>53580.00</td>\n",
       "      <td>14592.316888</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>7.818563e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1619568000</td>\n",
       "      <td>53887.00</td>\n",
       "      <td>56476.17</td>\n",
       "      <td>55069.61</td>\n",
       "      <td>54894.03</td>\n",
       "      <td>16484.336777</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>9.048917e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1619481600</td>\n",
       "      <td>53321.00</td>\n",
       "      <td>55509.39</td>\n",
       "      <td>54047.80</td>\n",
       "      <td>55069.62</td>\n",
       "      <td>13957.086495</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>7.686114e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1619395200</td>\n",
       "      <td>48817.62</td>\n",
       "      <td>54400.00</td>\n",
       "      <td>49121.00</td>\n",
       "      <td>54053.60</td>\n",
       "      <td>18005.223994</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>9.732472e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1619308800</td>\n",
       "      <td>47044.01</td>\n",
       "      <td>50591.38</td>\n",
       "      <td>50101.42</td>\n",
       "      <td>49121.00</td>\n",
       "      <td>14633.512065</td>\n",
       "      <td>2021-04-25</td>\n",
       "      <td>7.188127e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           unix       low      high      open     close        volume  \\\n",
       "0    1645142400  40323.85  40972.30  40537.94  40659.51   3062.079456   \n",
       "1    1645056000  40099.99  44195.62  43895.55  40536.73  18630.108422   \n",
       "2    1644969600  43330.59  44585.69  44580.73  43895.56   9663.440404   \n",
       "3    1644883200  42433.28  44775.96  42548.71  44583.52  14154.734526   \n",
       "4    1644796800  41570.00  42876.15  42073.37  42548.71  14805.983388   \n",
       "..          ...       ...       ...       ...       ...           ...   \n",
       "295  1619654400  52369.61  55226.86  54889.81  53580.00  14592.316888   \n",
       "296  1619568000  53887.00  56476.17  55069.61  54894.03  16484.336777   \n",
       "297  1619481600  53321.00  55509.39  54047.80  55069.62  13957.086495   \n",
       "298  1619395200  48817.62  54400.00  49121.00  54053.60  18005.223994   \n",
       "299  1619308800  47044.01  50591.38  50101.42  49121.00  14633.512065   \n",
       "\n",
       "           date      vol_fiat  \n",
       "0    2022-02-18  1.245027e+08  \n",
       "1    2022-02-17  7.552037e+08  \n",
       "2    2022-02-16  4.241821e+08  \n",
       "3    2022-02-15  6.310679e+08  \n",
       "4    2022-02-14  6.299755e+08  \n",
       "..          ...           ...  \n",
       "295  2021-04-29  7.818563e+08  \n",
       "296  2021-04-28  9.048917e+08  \n",
       "297  2021-04-27  7.686114e+08  \n",
       "298  2021-04-26  9.732472e+08  \n",
       "299  2021-04-25  7.188127e+08  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a simulation to see what happened\n",
    "data = env.data\n",
    "actions = np.array(val_memory, dtype=object)[:, 1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a528572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836860f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
