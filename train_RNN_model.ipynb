{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40915ae3",
   "metadata": {},
   "source": [
    "## Main file for training and saving an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf061b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d5d5b",
   "metadata": {},
   "source": [
    "### Import the agent and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8746a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Environment import cryptoTrade\n",
    "\n",
    "from networks.Deep_RL_agents import RNN_agent, convet_to_ragged_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b65548",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd049278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, memory, model, target_model, done):\n",
    "    learning_rate = 0.7\n",
    "    discount_factor = 0.9\n",
    "    \n",
    "    MIN_REPLAY_SIZE = 1000\n",
    "    if len(memory) < MIN_REPLAY_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_size = 64\n",
    "    mini_batch_indexes = np.random.choice(np.arange(len(memory)), size=batch_size, replace=False)\n",
    "\n",
    "    current_states = [memory[i][0] for i in mini_batch_indexes]\n",
    "    current_qs_list = model.predict(convet_to_ragged_tensor(current_states, single=False))\n",
    "    \n",
    "    new_current_states = [memory[i][4] for i in mini_batch_indexes]\n",
    "    future_qs_list = target_model.predict(convet_to_ragged_tensor(new_current_states, single=False))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, i in enumerate(mini_batch_indexes):\n",
    "        (observation, action, actual_action, reward, new_observation, done) = memory[i]\n",
    "        if not done:\n",
    "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "        else:\n",
    "            max_future_q = reward\n",
    "\n",
    "        current_qs = current_qs_list[index]\n",
    "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\n",
    "\n",
    "        X.append(observation)\n",
    "        Y.append(current_qs)\n",
    "    \n",
    "    X = convet_to_ragged_tensor(X, single=False)\n",
    "    model.fit(X, np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ff177",
   "metadata": {},
   "source": [
    "### Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887bd785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 20:17:50.319287: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-04 20:17:50.319377: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Create the env and the model\n",
    "data_path = \"data/Coinbase_BTCUSD_dailydata.csv\"\n",
    "env = cryptoTrade(data_path)\n",
    "env.reset()\n",
    "\n",
    "model = RNN_agent(env.observation_space, env.action_space)\n",
    "target_model = RNN_agent(env.observation_space, env.action_space)\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb27e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch rewards (profit): 3.04e+07 after 0 steps\n",
      "Total epoch rewards (profit): 3.44e+07 after 1 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 20:17:50.655390: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-04 20:17:50.656051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 20:17:50.700516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch rewards (profit): -1.54e+06 after 2 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 20:17:50.940190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 20:17:50.976057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 20:17:51.436014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 20:17:51.558998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 20:17:51.640199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch rewards (profit): 1.11e+07 after 3 steps\n",
      "Total epoch rewards (profit): 4.06e+07 after 4 steps\n",
      "Total epoch rewards (profit): 3.77e+07 after 5 steps\n",
      "Total epoch rewards (profit): -2.08e+06 after 6 steps\n",
      "Total epoch rewards (profit): 4.83e+07 after 7 steps\n",
      "Total epoch rewards (profit): 3.57e+07 after 8 steps\n",
      "Total epoch rewards (profit): 2.09e+07 after 9 steps\n"
     ]
    }
   ],
   "source": [
    "# The main loop\n",
    "epsilon, max_epsilon, min_epsilon = 1, 1, 0.01\n",
    "decay = 0.01\n",
    "\n",
    "memory = []\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "steps_to_update_target_model = 0\n",
    "for episode in range(10):\n",
    "    total_training_rewards = 0\n",
    "    \n",
    "    observation = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        steps_to_update_target_model += 1\n",
    "\n",
    "        # Implement epsilon greedy learning\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = int(np.random.choice(len(env.action_space)))\n",
    "        else: \n",
    "            action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "            \n",
    "        # Now step the simulation\n",
    "        actual_action, new_observation, reward, done = env.step(action)\n",
    "        memory.append([observation, action, actual_action, reward, new_observation, done])\n",
    "        \n",
    "        # Update the neural network\n",
    "        if (steps_to_update_target_model % 4 == 0) or done:\n",
    "            train(env, memory, model, target_model, done)\n",
    "            \n",
    "        observation = new_observation\n",
    "        total_training_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            print('Total epoch rewards (profit): {:.2e} after {} steps'.format(total_training_rewards, episode))\n",
    "\n",
    "            if steps_to_update_target_model >= 100:\n",
    "#                 print('Copying main network weights to the target network weights')\n",
    "                target_model.set_weights(model.get_weights())\n",
    "                steps_to_update_target_model = 0\n",
    "            break\n",
    "        \n",
    "    # Update epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "\n",
    "# target_model.save('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6642d0c",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc314310",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "done = False\n",
    "val_memory = []\n",
    "\n",
    "while not done:\n",
    "    action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "    actual_action, new_observation, reward, done = env.step(action)\n",
    "    \n",
    "    info = {\"observation\":observation.copy(), \"action\":action, \"actual_action\":actual_action, \n",
    "            \"reward\":reward, \"new_observation\":new_observation.copy(), \"done\":done}\n",
    "    val_memory.append(info)\n",
    "    observation = new_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e018e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "observations = [x[\"observation\"] for x in val_memory]\n",
    "actions = [x[\"action\"] for x in val_memory]\n",
    "actual_actions = [x[\"actual_action\"] for x in val_memory]\n",
    "rewards = [x[\"reward\"] for x in val_memory]\n",
    "new_observations = [x[\"new_observation\"] for x in val_memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8193ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n",
      "-4 -870.0799999999872\n",
      "6 -870.0799999999872\n",
      "-10 -20995.76000000004\n",
      "6 -20995.76000000004\n",
      "8 -20995.76000000004\n",
      "6 -20995.76000000004\n",
      "3 -20995.76000000004\n",
      "0 -20995.76000000004\n",
      "0 -20995.76000000004\n",
      "0 -20995.76000000004\n",
      "0 -20995.76000000004\n",
      "-10 -58290.040000000125\n",
      "-4 -60247.16000000015\n",
      "-10 -64081.08000000019\n",
      "6 -64081.08000000019\n",
      "7 -64081.08000000019\n",
      "3 -64081.08000000019\n",
      "6 -64081.08000000019\n",
      "2 -64081.08000000019\n",
      "-4 -46180.8400000002\n",
      "4 -46180.8400000002\n",
      "0 -46180.8400000002\n",
      "-4 -20125.910000000207\n",
      "4 -20125.910000000207\n",
      "0 -20125.910000000207\n",
      "0 -20125.910000000207\n",
      "0 -20125.910000000207\n",
      "-4 5757.969999999797\n",
      "4 5757.969999999797\n",
      "-10 64474.23999999976\n",
      "9 64474.23999999976\n",
      "1 64474.23999999976\n",
      "-10 78739.39999999979\n",
      "-10 94281.11999999988\n",
      "6 94281.11999999988\n",
      "-4 113379.99999999988\n",
      "6 113379.99999999988\n",
      "10 113379.99999999988\n",
      "0 113379.99999999988\n",
      "0 113379.99999999988\n",
      "0 113379.99999999988\n",
      "-4 124543.34999999986\n",
      "-4 142671.52999999982\n",
      "0 142671.52999999982\n",
      "-4 155188.48999999982\n",
      "6 155188.48999999982\n",
      "6 155188.48999999982\n",
      "0 155188.48999999982\n",
      "0 155188.48999999982\n",
      "0 155188.48999999982\n",
      "0 155188.48999999982\n",
      "-4 152126.96999999983\n",
      "4 152126.96999999983\n",
      "-10 141781.01999999981\n",
      "6 141781.01999999981\n",
      "-4 131854.39999999985\n",
      "3 131854.39999999985\n",
      "5 131854.39999999985\n",
      "0 131854.39999999985\n",
      "-4 117169.35999999987\n",
      "-10 112921.55999999976\n",
      "9 112921.55999999976\n",
      "4 112921.55999999976\n",
      "-4 125971.34999999974\n",
      "3 125971.34999999974\n",
      "1 125971.34999999974\n",
      "-10 159305.1499999998\n",
      "9 159305.1499999998\n",
      "0 159305.1499999998\n",
      "-10 225635.7699999998\n",
      "-10 253119.34999999974\n",
      "6 253119.34999999974\n",
      "6 253119.34999999974\n",
      "3 253119.34999999974\n",
      "-4 260595.45999999976\n",
      "9 260595.45999999976\n",
      "1 260595.45999999976\n",
      "0 260595.45999999976\n",
      "0 260595.45999999976\n",
      "0 260595.45999999976\n",
      "-10 287553.57999999984\n",
      "-10 291716.95999999973\n",
      "2 291716.95999999973\n",
      "4 291716.95999999973\n",
      "-4 310782.7899999997\n",
      "-4 332370.94999999966\n",
      "10 332370.94999999966\n",
      "-10 329849.8499999997\n",
      "6 329849.8499999997\n",
      "3 329849.8499999997\n",
      "3 329849.8499999997\n",
      "8 329849.8499999997\n",
      "-4 323856.00999999966\n",
      "-10 278953.6699999996\n",
      "-4 252758.9099999996\n",
      "6 252758.9099999996\n",
      "8 252758.9099999996\n",
      "3 252758.9099999996\n",
      "0 252758.9099999996\n",
      "-4 240134.9499999996\n",
      "3 240134.9499999996\n",
      "1 240134.9499999996\n",
      "0 240134.9499999996\n",
      "-10 201299.18999999936\n",
      "-4 190245.82999999935\n",
      "6 190245.82999999935\n",
      "8 190245.82999999935\n",
      "-10 176607.7699999993\n",
      "5 176607.7699999993\n",
      "5 176607.7699999993\n",
      "0 176607.7699999993\n",
      "0 176607.7699999993\n",
      "-4 179130.4299999993\n",
      "4 179130.4299999993\n",
      "0 179130.4299999993\n",
      "0 179130.4299999993\n",
      "-10 145014.92999999918\n",
      "6 145014.92999999918\n",
      "4 145014.92999999918\n",
      "0 145014.92999999918\n",
      "0 145014.92999999918\n",
      "0 145014.92999999918\n",
      "0 145014.92999999918\n",
      "0 145014.92999999918\n",
      "-4 117556.7699999992\n",
      "3 117556.7699999992\n",
      "1 117556.7699999992\n",
      "0 117556.7699999992\n",
      "0 117556.7699999992\n",
      "-4 63434.459999999235\n",
      "5 63434.459999999235\n",
      "-10 -95090.27000000069\n",
      "6 -95090.27000000069\n",
      "4 -95090.27000000069\n",
      "0 -95090.27000000069\n",
      "0 -95090.27000000069\n",
      "0 -95090.27000000069\n",
      "-4 -125986.98000000068\n",
      "4 -125986.98000000068\n",
      "-4 -143827.41000000067\n",
      "-10 -131846.5100000007\n",
      "6 -131846.5100000007\n",
      "6 -131846.5100000007\n",
      "-10 -106479.11000000068\n",
      "6 -106479.11000000068\n",
      "4 -106479.11000000068\n",
      "0 -106479.11000000068\n",
      "0 -106479.11000000068\n",
      "0 -106479.11000000068\n",
      "-4 -116932.75000000067\n",
      "4 -116932.75000000067\n",
      "-10 -132709.95000000074\n",
      "8 -132709.95000000074\n",
      "-10 -127883.95000000074\n",
      "3 -127883.95000000074\n",
      "8 -127883.95000000074\n",
      "-10 -114701.91000000064\n",
      "7 -114701.91000000064\n",
      "3 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "0 -114701.91000000064\n",
      "-10 -159642.40000000058\n",
      "6 -159642.40000000058\n",
      "5 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "0 -159642.40000000058\n",
      "-4 -177359.76000000056\n",
      "3 -177359.76000000056\n",
      "-10 -199825.93000000055\n",
      "9 -199825.93000000055\n",
      "1 -199825.93000000055\n",
      "-10 -242393.3100000005\n",
      "7 -242393.3100000005\n",
      "4 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "0 -242393.3100000005\n",
      "-4 -263060.75000000047\n",
      "3 -263060.75000000047\n",
      "-4 -293214.38000000047\n",
      "3 -293214.38000000047\n",
      "3 -293214.38000000047\n",
      "-10 -361437.2000000005\n",
      "6 -361437.2000000005\n",
      "4 -361437.2000000005\n",
      "0 -361437.2000000005\n",
      "0 -361437.2000000005\n",
      "0 -361437.2000000005\n",
      "-3 -379061.3300000005\n",
      "3 -379061.3300000005\n",
      "-10 -383229.00000000047\n",
      "6 -383229.00000000047\n",
      "4 -383229.00000000047\n",
      "0 -383229.00000000047\n",
      "0 -383229.00000000047\n",
      "-4 -371794.66000000044\n",
      "4 -371794.66000000044\n",
      "-10 -351878.1200000005\n",
      "6 -351878.1200000005\n",
      "4 -351878.1200000005\n",
      "0 -351878.1200000005\n",
      "0 -351878.1200000005\n",
      "0 -351878.1200000005\n",
      "-10 -347545.09000000055\n",
      "6 -347545.09000000055\n",
      "-4 -340830.8900000006\n",
      "-10 -340215.54000000056\n",
      "3 -340215.54000000056\n",
      "9 -340215.54000000056\n",
      "-10 -357108.0700000006\n",
      "3 -357108.0700000006\n",
      "6 -357108.0700000006\n",
      "6 -357108.0700000006\n",
      "1 -357108.0700000006\n",
      "-4 -346245.10000000056\n",
      "3 -346245.10000000056\n",
      "-10 -324343.0000000006\n",
      "8 -324343.0000000006\n",
      "2 -324343.0000000006\n",
      "0 -324343.0000000006\n",
      "0 -324343.0000000006\n",
      "0 -324343.0000000006\n",
      "0 -324343.0000000006\n",
      "-4 -305142.72000000055\n",
      "4 -305142.72000000055\n",
      "0 -305142.72000000055\n",
      "0 -305142.72000000055\n",
      "-4 -308903.27000000054\n",
      "4 -308903.27000000054\n",
      "-10 -334971.7300000005\n",
      "8 -334971.7300000005\n",
      "2 -334971.7300000005\n",
      "0 -334971.7300000005\n",
      "0 -334971.7300000005\n",
      "0 -334971.7300000005\n",
      "0 -334971.7300000005\n",
      "-10 -352384.6900000006\n",
      "8 -352384.6900000006\n",
      "-10 -337813.0500000005\n",
      "6 -337813.0500000005\n",
      "5 -337813.0500000005\n",
      "-10 -320283.1900000005\n",
      "7 -320283.1900000005\n",
      "3 -320283.1900000005\n",
      "1 -320283.1900000005\n",
      "0 -320283.1900000005\n",
      "-10 -327637.2100000005\n",
      "8 -327637.2100000005\n",
      "0 -327637.2100000005\n",
      "0 -327637.2100000005\n",
      "-10 -234402.35000000056\n",
      "5 -234402.35000000056\n",
      "5 -234402.35000000056\n",
      "-10 -196131.47000000055\n",
      "3 -196131.47000000055\n",
      "6 -196131.47000000055\n",
      "0 -196131.47000000055\n",
      "0 -196131.47000000055\n",
      "0 -196131.47000000055\n",
      "0 -196131.47000000055\n",
      "0 -196131.47000000055\n",
      "-10 -188182.2800000006\n",
      "5 -188182.2800000006\n",
      "4 -188182.2800000006\n",
      "0 -188182.2800000006\n",
      "0 -188182.2800000006\n",
      "0 -188182.2800000006\n",
      "0 -188182.2800000006\n",
      "0 -188182.2800000006\n",
      "0 -188182.2800000006\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rewards)):\n",
    "    print(actual_actions[i], rewards[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPAND THE DATA WE ARE USING\n",
    "# TEST ON TESTING DATASET\n",
    "# PLOT THE RESULTS\n",
    "# CREATE BUY SELL ANIMATION\n",
    "# DO A DNN AFTER EVAL IS CREATED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
