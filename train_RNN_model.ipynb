{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40915ae3",
   "metadata": {},
   "source": [
    "## Main file for training and saving an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf061b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d5d5b",
   "metadata": {},
   "source": [
    "### Import the agent and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8746a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Environment import cryptoTrade\n",
    "\n",
    "from networks.Deep_RL_agents import RNN_agent, convet_to_ragged_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b65548",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd049278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, memory, model, target_model, done):\n",
    "    learning_rate = 0.7\n",
    "    discount_factor = 0.9\n",
    "    \n",
    "    MIN_REPLAY_SIZE = 1000\n",
    "    if len(memory) < MIN_REPLAY_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_size = 64\n",
    "    mini_batch_indexes = np.random.choice(np.arange(len(memory)), size=batch_size, replace=False)\n",
    "\n",
    "    current_states = [memory[i][0] for i in mini_batch_indexes]\n",
    "    current_qs_list = model.predict(convet_to_ragged_tensor(current_states, single=False))\n",
    "    \n",
    "    new_current_states = [memory[i][4] for i in mini_batch_indexes]\n",
    "    future_qs_list = target_model.predict(convet_to_ragged_tensor(new_current_states, single=False))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, i in enumerate(mini_batch_indexes):\n",
    "        (observation, action, actual_action, reward, new_observation, done) = memory[i]\n",
    "        if not done:\n",
    "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "        else:\n",
    "            max_future_q = reward\n",
    "\n",
    "        current_qs = current_qs_list[index]\n",
    "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\n",
    "\n",
    "        X.append(observation)\n",
    "        Y.append(current_qs)\n",
    "    \n",
    "    X = convet_to_ragged_tensor(X, single=False)\n",
    "    model.fit(X, np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ff177",
   "metadata": {},
   "source": [
    "### Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887bd785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                19200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,565\n",
      "Trainable params: 20,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 01:27:22.970446: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-06 01:27:22.970601: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Create the env and the model\n",
    "training_data_path = \"data/training_2015_2021.df\"\n",
    "env = cryptoTrade(training_data_path, episode_size=720)\n",
    "\n",
    "model = RNN_agent(env.observation_space, env.action_space)\n",
    "model.summary()\n",
    "target_model = RNN_agent(env.observation_space, env.action_space)\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb27e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch rewards (profit): 1.05e+04 after 0 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 01:27:24.281871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-06 01:27:24.282556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:24.323812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:24.598440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:24.634609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:25.239116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:25.361548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-06 01:27:25.522591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch rewards (profit): -1.32e+04 after 1 steps\n",
      "Total epoch rewards (profit): -4.80e+03 after 2 steps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Update the neural network\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (steps_to_update_target_model \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m done:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m observation \u001b[38;5;241m=\u001b[39m new_observation\n\u001b[1;32m     34\u001b[0m total_training_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, memory, model, target_model, done)\u001b[0m\n\u001b[1;32m     30\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(observation)\n\u001b[1;32m     31\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(current_qs)\n\u001b[0;32m---> 33\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mconvet_to_ragged_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, np\u001b[38;5;241m.\u001b[39marray(Y), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/CISC_856/networks/Deep_RL_agents.py:49\u001b[0m, in \u001b[0;36mconvet_to_ragged_tensor\u001b[0;34m(obs, single)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     47\u001b[0m             obs[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m([value])\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mragged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:82\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(pylist, dtype, ragged_rank, inner_shape, name, row_splits_dtype)\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ragged_tensor\u001b[38;5;241m.\u001b[39mRaggedTensor\u001b[38;5;241m.\u001b[39mfrom_row_splits(values, row_splits,\n\u001b[1;32m     79\u001b[0m                                                     validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaggedConstant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mragged_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpylist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mragged_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:186\u001b[0m, in \u001b[0;36m_constant_value\u001b[0;34m(ragged_factory, inner_factory, pylist, dtype, ragged_rank, inner_shape)\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    183\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid ragged_rank=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: must be nonnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ragged_rank)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Find the depth of scalar values in `pylist`.\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m scalar_depth, max_depth \u001b[38;5;241m=\u001b[39m \u001b[43m_find_scalar_and_max_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpylist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m max_depth \u001b[38;5;241m>\u001b[39m scalar_depth:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:263\u001b[0m, in \u001b[0;36m_find_scalar_and_max_depth\u001b[0;34m(pylist)\u001b[0m\n\u001b[1;32m    261\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m pylist:\n\u001b[0;32m--> 263\u001b[0m   child_scalar_depth, child_max_depth \u001b[38;5;241m=\u001b[39m \u001b[43m_find_scalar_and_max_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m child_scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scalar_depth \u001b[38;5;241m!=\u001b[39m child_scalar_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:263\u001b[0m, in \u001b[0;36m_find_scalar_and_max_depth\u001b[0;34m(pylist)\u001b[0m\n\u001b[1;32m    261\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m pylist:\n\u001b[0;32m--> 263\u001b[0m   child_scalar_depth, child_max_depth \u001b[38;5;241m=\u001b[39m \u001b[43m_find_scalar_and_max_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m child_scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scalar_depth \u001b[38;5;241m!=\u001b[39m child_scalar_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:263\u001b[0m, in \u001b[0;36m_find_scalar_and_max_depth\u001b[0;34m(pylist)\u001b[0m\n\u001b[1;32m    261\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m pylist:\n\u001b[0;32m--> 263\u001b[0m   child_scalar_depth, child_max_depth \u001b[38;5;241m=\u001b[39m \u001b[43m_find_scalar_and_max_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m child_scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scalar_depth \u001b[38;5;241m!=\u001b[39m child_scalar_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:259\u001b[0m, in \u001b[0;36m_find_scalar_and_max_depth\u001b[0;34m(pylist)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"Finds nesting depth of scalar values in pylist.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m  ValueError: If pylist has inconsistent nesting depths for scalars.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Check if pylist is not scalar. np.ndim builds an array, so we\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# short-circuit lists and tuples.\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pylist, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpylist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    260\u001b[0m   scalar_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m   max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3196\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_ndim_dispatcher)\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mndim\u001b[39m(a):\n\u001b[1;32m   3166\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3167\u001b[0m \u001b[38;5;124;03m    Return the number of dimensions of an array.\u001b[39;00m\n\u001b[1;32m   3168\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3194\u001b[0m \n\u001b[1;32m   3195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m   3198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The main loop\n",
    "epsilon, max_epsilon, min_epsilon = 1, 1, 0.01\n",
    "decay = 0.01\n",
    "\n",
    "memory = []\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "steps_to_update_target_model = 0\n",
    "for episode in range(10):\n",
    "    total_training_rewards = 0\n",
    "    \n",
    "    observation = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        steps_to_update_target_model += 1\n",
    "\n",
    "        # Implement epsilon greedy learning\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = int(np.random.choice(len(env.action_space)))\n",
    "        else: \n",
    "            action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "            \n",
    "        # Now step the simulation\n",
    "        actual_action, new_observation, reward, done = env.step(action)\n",
    "        memory.append([observation, action, actual_action, reward, new_observation, done])\n",
    "        \n",
    "        # Update the neural network\n",
    "        if (steps_to_update_target_model % 4 == 0) or done:\n",
    "            train(env, memory, model, target_model, done)\n",
    "            \n",
    "        observation = new_observation\n",
    "        total_training_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            #print('Total epoch rewards (profit): {:.2e} after {} steps'.format(total_training_rewards, episode))\n",
    "            print('Total epoch rewards (profit): {:.2e} after {} steps'.format(reward, episode))\n",
    "\n",
    "            if steps_to_update_target_model >= 100:\n",
    "#                 print('Copying main network weights to the target network weights')\n",
    "                target_model.set_weights(model.get_weights())\n",
    "                steps_to_update_target_model = 0\n",
    "            break\n",
    "        \n",
    "    # Update epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "\n",
    "# target_model.save('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6642d0c",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc314310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the env and the model\n",
    "testing_data_path = \"data/testing_2022.df\"\n",
    "testing_env = cryptoTrade(testing_data_path, episode_size=720)\n",
    "\n",
    "observation = testing_env.reset()\n",
    "done = False\n",
    "val_memory = []\n",
    "\n",
    "while not done:\n",
    "    action = int(model.predict(convet_to_ragged_tensor(observation, single=True)).argmax())\n",
    "    actual_action, new_observation, reward, done = testing_env.step(action)\n",
    "    \n",
    "    info = {\"observation\":observation.copy(), \"action\":action, \"actual_action\":actual_action, \n",
    "            \"reward\":reward, \"new_observation\":new_observation.copy(), \"done\":done}\n",
    "    val_memory.append(info)\n",
    "    \n",
    "    observation = new_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e018e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "observations = [x[\"observation\"] for x in val_memory]\n",
    "actions = [x[\"action\"] for x in val_memory]\n",
    "actual_actions = [x[\"actual_action\"] for x in val_memory]\n",
    "rewards = [x[\"reward\"] for x in val_memory]\n",
    "new_observations = [x[\"new_observation\"] for x in val_memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6327ffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(rewards)\n",
    "plt.title(\"Profits over a random 12h interval\")\n",
    "plt.xlabel(\"Minutes\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPAND THE DATA WE ARE USING\n",
    "# TEST ON TESTING DATASET\n",
    "# PLOT THE RESULTS\n",
    "# CREATE BUY SELL ANIMATION\n",
    "# DO A DNN AFTER EVAL IS CREATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8da4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for i, j in itertools.product(range(10), range(10, 21)):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65815d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7567d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
